<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Accelerating CTC Beam Search Decoding on GPUs using CUDA</title>

  <link
    rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"
    integrity="sha384-n8MVd4RsNIU0KOVEMmg9rtabNEJFvmbFe7aiCKzADTLpiOKgDCqUlkggVCiduneo"
    crossorigin="anonymous"
  />

  <script
    defer
    src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"
    integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8"
    crossorigin="anonymous"
  ></script>

  <script
    defer
    src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05"
    crossorigin="anonymous"
  ></script>

  <script>
    window.addEventListener("DOMContentLoaded", function () {
      renderMathInElement(document.body, {
        delimiters: [
          {left: '$$', right: '$$', display: true},
          {left: '$', right: '$', display: false},
          {left: '\\(', right: '\\)', display: false},
          {left: '\\[', right: '\\]', display: true}
        ],
        throwOnError : false
      });
    });
  </script>

  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <nav class="nav-tabs">
    <a href="index.html" class="nav-link active">Proposal</a>
    <a href="milestone.html" class="nav-link">Milestone</a>
  </nav>

  <div class="header-main">
    <h1>Accelerating CTC Beam Search Decoding on GPUs using CUDA</h1>
    <p class="subtitle">15-418 Project Proposal</p>
    <p class="authors">Julius Arolovitch, Ben Kleyner, Maxim Yagnyatinskiy</p>
    <p class="date">Fall 2025</p>
  </div>

  <h2>Summary</h2>

  <p>
    We will implement a high-performance batched CTC Beam Search decoder in CUDA to
    accelerate autoregressive sequence decoding tasks on NVIDIA GPUs. The project will
    focus on optimizing the iterative decoding loop by developing custom device-side
    kernels for massively parallel hypothesis expansion and an efficient parallel
    top-k selection algorithm for beam pruning.
  </p>

  <h2>Background</h2>

  <p>
    Connectionist Temporal Classification (CTC) is an output layer and loss function
    used in training recurrent neural networks (RNNs) for sequence-to-sequence tasks,
    such as speech recognition or handwriting recognition. Its key advantage is that it
    does not require a frame-by-frame alignment between the input sequence and the
    output sequence. A network trained with CTC outputs a probability distribution for
    each time step over the set of possible output labels, plus a special blank token.
    The decoding task is to find the most probable output sequence from this
    <em>T</em> × <em>N</em> matrix of probabilities, whereby <em>T</em> is the number
    of time steps and <em>N</em> is the number of labels.
  </p>

  <p>
    The simplest method is greedy decoding, which takes the most probable label at each
    time step and then collapses repeated labels and removes blanks. This is
    computationally trivial but often suboptimal.
  </p>

  <p>
    CTC Beam Search Decoding is a more effective algorithm that provides more accurate
    transcriptions. Instead of just tracking the single best path, it maintains a
    “beam” of the \(k\) most probable candidate sequences at each time step. At
    each step \(t\), it explores extending these \(k\) hypotheses with all
    possible labels, calculates their new probabilities, and merges paths that result
    in the same output sequence. The beam is then pruned back to the \(k\) most
    likely hypotheses to carry forward to step \(t+1\).
  </p>

  <p>
    The aspects of this problem that benefit from parallelism are two-fold. First, as
    our summary suggests, the entire decoding process for one sequence can be run in
    parallel with other sequences in a batch. This provides a high level of
    coarse-grained data parallelism. Second, within a single sequence’s decoding at
    each time step \(t\), we can explore all \(k \times N\) possible
    extensions in parallel. The challenge, as detailed below, lies in the
    synchronization, merging, and pruning steps that follow.
  </p>

  <h2>Challenge</h2>

  <p>
    The core challenge is mapping this dynamic, irregular, and memory-bound algorithm
    onto the rigid, data-parallel SIMT architecture of a GPU. The workload has several
    particular characteristics that make it difficult to parallelize.
  </p>

  <p>
    First, the probability of a new hypothesis at time \(t\) is not independent.
    It depends on the probabilities of its prefix at time \(t-1\), as well as the
    CTC merging logic. This requires synchronization and careful management of state.
  </p>

  <p>
    Additionally, the “fan-out” step of extending \(k\) hypotheses to
    \(k \times N\) new ones has poor spatial locality; threads in a warp may
    access scattered locations in the \(T \times N\) probability matrix and in
    the beam data structures. The “merge” step requires a many-to-one reduction, which
    is also memory-intensive and requires synchronization. This leads to a low
    computation-to-communication ratio; the kernel will be dominated by memory
    operations and sorting, not arithmetic.
  </p>

  <p>
    Finally, the number of active, non-pruned hypotheses can vary significantly at each
    time step. Furthermore, the merging logic is data-dependent. This leads to
    significant thread divergence within a warp, as some threads may be performing
    complex merge operations while others are idle. This load imbalance is a poor fit
    for the SIMT model.
  </p>

  <p>
    In short, the GPU execution model thrives on uniform, arithmetic-heavy tasks with
    high data locality; our problem is opposite in almost every respect.
  </p>

  <h2>Resources</h2>

  <p>
    We will be developing our code primarily on the GHC cluster machines which are
    equipped with CUDA capable GPUs. The results on these machines will be compared
    with experimentation on the PSC machines which have considerably more powerful
    GPUs.
  </p>

  <p>
    Our initial implementation of the beam search algorithm will be based on the
    pseudocode in
    <a href="https://arxiv.org/abs/2204.02929" target="_blank" rel="noopener noreferrer">
      this paper
    </a>.
  </p>

  <h2>Goals and Deliverables</h2>

  <table>
    <thead>
      <tr>
        <th>Completion</th>
        <th>Goal Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>MVP</strong></td>
        <td>
          Implement a correct, batched CTC beam search decoder on GPU that outperforms
          a correct CPU implementation. This includes basic kernels for hypothesis
          expansion and sequential top-k pruning within each thread block.
        </td>
      </tr>
      <tr>
        <td><strong>MLP</strong></td>
        <td>
          Optimize the batched decoder to achieve significant speedup over a CPU
          baseline, focusing on efficient parallel top-k selection and improved memory
          access patterns. Implement shared memory optimizations and basic warp-level
          intrinsics.
        </td>
      </tr>
      <tr>
        <td><strong>Stretch</strong></td>
        <td>
          Develop advanced load-balancing techniques for handling thread divergence due
          to data-dependent merging, explore dynamic parallelism or kernel fusion, and
          integrate with a simple deep learning framework (e.g., PyTorch, TensorFlow)
          for real-world inference.
        </td>
      </tr>
    </tbody>
  </table>

  <h2>Platform</h2>

  <p>
    The deployment of beam search decoders has shifted from CPU-centric logic to hybrid
    CPU-GPU systems, driven by the developments in GPU-native neural network
    approaches. This hybrid model, however, is fundamentally limited by the data
    transfer between the CPU and GPU at every decoding step. This bottleneck becomes
    more relevant due to the asymmetric scaling of on-device GPU performance versus
    off-device I/O speed. Driven by specialized hardware like NVIDIA’s Tensor Cores
    and massive increases in memory bandwidth, the effective computational speed of
    GPUs has increased much faster than the PCIe bus which has seen only modest,
    linear improvements. This creates a classic scenario where overall system speedup
    is constrained by its slowest component, as stipulated by Amdahl’s Law.
  </p>

  <p>
    Let \(T_{\text{step}}\) be the total time for a single decoding step. Let
    \(S\) represent the effective speedup of the on-device (GPU) parallelizable
    portion of the task, which accounts for all GPU architectural improvements (cores,
    specialized hardware, and memory bandwidth). The transition from an early GPU
    generation (\(G_1\)) to a modern one (\(G_2\)) can be modeled as follows:
  </p>

  \[
  \begin{aligned}
    T_{\text{step}} &= T_{\text{compute}} + T_{\text{transfer}} \\
    \text{Given } T_{\text{compute}}(G_2) &= \frac{T_{\text{compute}}(G_1)}{S} \text{ where } S \gg 1 \\
    \text{and } T_{\text{transfer}}(G_2) &\approx T_{\text{transfer}}(G_1)
  \end{aligned}
  \]

  <p>
    The fraction of time spent on data transfer, \(f\), consequently shifts from
    \(f_1\) to \(f_2\):
  </p>

  \[
  f_1 = \frac{T_{\text{transfer}}(G_1)}
             {T_{\text{compute}}(G_1) + T_{\text{transfer}}(G_1)}
  \longrightarrow
  f_2 \approx \frac{T_{\text{transfer}}(G_1)}
                     {\frac{T_{\text{compute}}(G_1)}{S} + T_{\text{transfer}}(G_1)}
  \]

  <p>
    As the effective speedup \(S\) grows, the effect of
    \(T_{\text{compute}}(G_1)/S\) is diminished and
    the transfer begins to dominate. Consequently, in this project we will attempt to
    maximize the fraction of computation that can be performed efficiently on-device to
    attempt to minimize the effect of the transfer term on overall performance.
  </p>

  <h2>Schedule</h2>

  <table>
    <thead>
      <tr>
        <th>Expected Completion Date</th>
        <th>Goal</th>
        <th>Assignee(s)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Monday, November 24</td>
        <td>MVP Complete</td>
        <td>TBD</td>
      </tr>
      <tr>
        <td>Monday, December 1</td>
        <td>MLP Complete</td>
        <td>TBD</td>
      </tr>
      <tr>
        <td>Sunday, December 7</td>
        <td>Stretch, Presentation, &amp; Report</td>
        <td>TBD</td>
      </tr>
    </tbody>
  </table>

  <p>
    Exact work distribution is yet to be determined and will be filled in by the
    mid-project check in.
  </p>

</body>
</html>

